input_dim: 9
seq_length: 14
num_classes: 6
d_model: 64
n_head: 4
d_ffn: 128
nlayers: 3
dropout: 0.018
activation: relu
lr: 0.0016612
batch_size: 256
seed: 42
PositonalEncoding: false
